# SentimentInsightUAM

Sistema de scraping y anÃ¡lisis de reseÃ±as de profesores de la Universidad AutÃ³noma Metropolitana, Unidad Azcapotzalco. Este proyecto extrae informaciÃ³n del directorio oficial de la UAM y de perfiles en MisProfesores.com para anÃ¡lisis de sentimiento y visualizaciÃ³n de datos.

## ğŸ¯ CaracterÃ­sticas

- **ExtracciÃ³n de nombres**: Obtiene automÃ¡ticamente la lista de profesores del [Directorio UAM Azcapotzalco](https://sistemas.azc.uam.mx/Somos/Directorio/)
- **Scraping robusto**: Navega y extrae perfiles completos de MisProfesores.com con:
  - BÃºsqueda normalizada (sin acentos, case-insensitive)
  - NavegaciÃ³n directa por URL para evitar timeouts
  - PaginaciÃ³n automÃ¡tica de reseÃ±as
  - Reintentos con backoff exponencial
- **Scraping masivo**: Comando `scrape-all` para procesar todos los profesores automÃ¡ticamente
  - Procesamiento secuencial con delays inteligentes
  - DetecciÃ³n automÃ¡tica de cambios por profesor
  - Resumen de progreso en tiempo real
  - Manejo robusto de errores sin interrumpir el proceso
- **CachÃ© inteligente**: 
  - Detecta automÃ¡ticamente si un profesor ya fue scrapeado
  - Compara nÃºmero de reseÃ±as para detectar cambios
  - Evita re-scraping innecesario (eficiencia y respeto al servidor)
  - Permite forzar actualizaciÃ³n cuando sea necesario
- **Persistencia dual**:
  - HTML original guardado en `data/outputs/html/` (auditorÃ­a)
  - JSON estructurado en `data/outputs/profesores/` (consumo)
  - Nombres normalizados con slugify para consistencia
- **Parsing estructurado**: Extrae calificaciones, etiquetas, comentarios y metadatos
- **CLI interactivo**: Interfaz de lÃ­nea de comandos con menÃº de selecciÃ³n

## ğŸ“‹ Requisitos

- Python 3.11+
- Playwright (Chromium)
- BeautifulSoup4
- Dependencias listadas en `requirements.txt`

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/christianpm-gh/SentimentInsightUAM.git
cd SentimentInsightUAM
```

### 2. Crear entorno virtual

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
python -m playwright install chromium
```

### 4. Configurar variables de entorno (opcional)

```bash
# Crear archivo .env
echo HEADLESS=true > .env
```

## ğŸ’» Uso

### 1. Extraer nombres de profesores UAM

Obtiene la lista completa de profesores del Departamento de Sistemas de la UAM Azcapotzalco:

```bash
python -m src.cli nombres-uam
```

Esto generarÃ¡ automÃ¡ticamente `data/inputs/profesor_nombres.json` con la informaciÃ³n de todos los profesores.

### 2. Scrapear perfil de un profesor

**Modo interactivo** (recomendado):
```bash
python -m src.cli prof
```
Se mostrarÃ¡ un menÃº numerado con todos los profesores disponibles.

**Modo directo** (por nombre):
```bash
python -m src.cli prof --name "Juan PÃ©rez GarcÃ­a"
```

### 3. Scrapear todos los profesores

Procesa automÃ¡ticamente todos los profesores del directorio UAM con cachÃ© inteligente:

```bash
python -m src.cli scrape-all
```

**CaracterÃ­sticas del scraping masivo:**

- Procesa todos los profesores secuencialmente
- Aplica delays de 2-4 segundos entre profesores para evitar bloqueos
- Detecta automÃ¡ticamente si un profesor necesita actualizaciÃ³n
- Solo re-scrapea cuando hay cambios en el nÃºmero de reseÃ±as
- Muestra progreso en tiempo real con contador
- Maneja errores de forma individual sin detener el proceso completo
- Genera resumen final con estadÃ­sticas

**Salida ejemplo:**

```
Iniciando scraping de 150 profesores...
================================================================================

[1/150] Procesando: Juan Perez Garcia
  -> Scrapeado exitosamente (47 reseÃ±as)
  -> Esperando 2s antes del siguiente...

[2/150] Procesando: Maria Lopez Hernandez
  -> Cache vigente (32 reseÃ±as)
  -> Esperando 4s antes del siguiente...

[3/150] Procesando: Carlos Rodriguez Torres
  -> Detectados cambios: 28 -> ~35 reseÃ±as
  -> Scrapeado exitosamente (35 reseÃ±as)
  -> Esperando 2s antes del siguiente...

...

================================================================================
RESUMEN DE SCRAPING
================================================================================
Total profesores procesados: 150
Scrapeados exitosamente: 28
Obtenidos de cache: 119
Errores: 3
================================================================================
```

**PrevenciÃ³n de bloqueos:**

- Delays variables (no detectables como patrÃ³n automÃ¡tico)
- User agent realista configurado en el navegador
- Reintentos automÃ¡ticos con backoff exponencial (via tenacity)
- Timeouts apropiados para cada operaciÃ³n
- Respeto a los lÃ­mites del servidor

### 4. Salida de datos

El scraper implementa **persistencia automÃ¡tica** con dos formatos:

#### JSON estructurado (`data/outputs/profesores/nombre-profesor.json`)

```json
{
  "name": "Nombre del Profesor",
  "overall_quality": 9.5,
  "difficulty": 7.2,
  "recommend_percent": 95.0,
  "cached": false,
  "tags": [
    {"label": "EXCELENTE CLASE", "count": 25},
    {"label": "INSPIRA", "count": 18}
  ],
  "reviews": [
    {
      "date": "2024-01-15",
      "course": "Estructura de Datos",
      "overall": 10.0,
      "ease": 8.0,
      "attendance": "Obligatoria",
      "grade_received": "10",
      "interest": "Alta",
      "tags": ["BUENA ONDA", "ACCESIBLE"],
      "comment": "Excelente profesor, explica muy bien..."
    }
  ]
}
```

#### HTML original (`data/outputs/html/nombre-profesor.html`)

- Guardado para auditorÃ­a y anÃ¡lisis offline
- Permite re-parsing sin re-scraping
- Ãštil para debugging y mejora del parser

#### CachÃ© Inteligente

El sistema detecta automÃ¡ticamente si un profesor ya fue scrapeado:

```bash
# Primera vez: scraping completo
python -m src.cli prof --name "Juan PÃ©rez"
# âš™ Scrapeando Juan PÃ©rez (9 pÃ¡ginas)...
# âœ“ Guardado: HTML en juan-perez.html, JSON en juan-perez.json
# âœ“ Total reseÃ±as extraÃ­das: 43

# Segunda vez (sin cambios): usa cachÃ©
python -m src.cli prof --name "Juan PÃ©rez"
# âœ“ CachÃ© vigente para Juan PÃ©rez (43 reseÃ±as)
# Fuente: CachÃ©

# Si hay nuevas reseÃ±as: scraping automÃ¡tico
# âœ“ Detectados cambios para Juan PÃ©rez: 43 â†’ ~48 reseÃ±as
```

**Ventajas del cachÃ©:**
- âš¡ Respuesta instantÃ¡nea para profesores ya scrapeados
- ğŸŒ Reduce carga en servidores externos
- â™»ï¸ Evita scraping redundante
- ğŸ¯ Solo actualiza cuando detecta cambios

## ğŸ—ï¸ Arquitectura del Proyecto

```
SentimentInsightUAM/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py           # Paquete principal
â”‚   â”œâ”€â”€ cli.py                # Interfaz de lÃ­nea de comandos
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ browser.py        # Context manager de Playwright
â”‚   â”œâ”€â”€ uam/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ nombres_uam.py    # Scraper del directorio UAM
â”‚   â””â”€â”€ mp/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ parser.py         # Parser HTML de MisProfesores
â”‚       â””â”€â”€ scrape_prof.py    # Scraper con cachÃ© inteligente
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ inputs/               # Listas de profesores
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ html/             # HTML original (auditorÃ­a)
â”‚       â””â”€â”€ profesores/       # JSONs estructurados
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ TECHNICAL_DOCUMENTATION.md  # DocumentaciÃ³n tÃ©cnica completa
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                      # Variables de entorno (opcional)
â””â”€â”€ README.md
```

## ğŸ”§ MÃ³dulos Principales

### `src.uam.nombres_uam`

Extrae nombres de profesores del directorio oficial UAM usando:

- Playwright para navegaciÃ³n dinÃ¡mica
- Clic automÃ¡tico en "Ver mÃ¡s Profesorado"
- NormalizaciÃ³n de nombres con slugify

### `src.mp.parser`

Parser HTML especializado que extrae:

- Calificaciones (calidad, dificultad, recomendaciÃ³n)
- Etiquetas con contadores
- ReseÃ±as completas con metadatos
- Conteo automÃ¡tico de pÃ¡ginas

### `src.mp.scrape_prof`

Scraper robusto con:

- BÃºsqueda normalizada (elimina acentos)
- NavegaciÃ³n directa por href
- Esperas explÃ­citas de selectores
- PaginaciÃ³n automÃ¡tica por URL
- Manejo de errores con reintentos
- **CachÃ© inteligente**: Detecta cambios en reseÃ±as
- **Persistencia dual**: HTML + JSON
- **Eficiencia**: Evita re-scraping innecesario

### `src.cli`

CLI con tres comandos principales:

- `nombres-uam`: Extrae lista de profesores del directorio UAM
- `prof`: Scrapea perfil individual (interactivo o directo)
- `scrape-all`: Scrapea todos los profesores con cachÃ© inteligente

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno (`.env`)

```env
# Modo headless del navegador (true/false)
HEADLESS=true
```

## ğŸ“ Notas Importantes

- **Uso responsable**: Este scraper es para fines educativos. Respeta los TÃ©rminos de Servicio de los sitios web.
- **Rate limiting**: El cÃ³digo incluye delays aleatorios para evitar sobrecarga de servidores.
- **CachÃ© automÃ¡tico**: El sistema detecta automÃ¡ticamente si un profesor ya fue scrapeado y evita scraping redundante.
- **Persistencia**: Todos los datos se guardan en disco automÃ¡ticamente (HTML + JSON).
- **Timeouts**: Los timeouts estÃ¡n configurados para 45 segundos en navegaciÃ³n y 30 segundos en selectores.
- **PrÃ³ximas caracterÃ­sticas**: Persistencia en PostgreSQL y MongoDB, anÃ¡lisis de sentimiento con BERT.

## ğŸ”® PrÃ³ximas CaracterÃ­sticas

- [ ] Persistencia en PostgreSQL (datos estructurados)
- [ ] Persistencia en MongoDB (comentarios/opiniones)
- [ ] AnÃ¡lisis de sentimiento con BERT
- [ ] API REST para consulta de datos
- [ ] Jobs programados con scheduler
- [ ] Dashboard de visualizaciÃ³n

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, sigue el flujo de trabajo de Git establecido en `git_workflow.md`.

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto para fines educativos.

## ğŸ‘¥ Equipo

Desarrollado por el equipo de SentimentInsightUAM - UAM Azcapotzalco

---

**âš ï¸ Disclaimer**: Este proyecto es con fines educativos y de investigaciÃ³n. El uso debe cumplir con los TÃ©rminos de Servicio de los sitios web utilizados.
