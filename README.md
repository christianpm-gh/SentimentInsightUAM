# SentimentInsightUAM

Sistema de scraping y anÃ¡lisis de reseÃ±as de profesores de la **Universidad AutÃ³noma Metropolitana, Unidad Azcapotzalco**. Este proyecto extrae informaciÃ³n del directorio oficial de la UAM y de perfiles en MisProfesores.com para anÃ¡lisis de sentimiento y visualizaciÃ³n de datos.

**VersiÃ³n**: 1.2.1 | [CHANGELOG](CHANGELOG.md)

---

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura](#-arquitectura)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Flujos CrÃ­ticos](#-flujos-crÃ­ticos)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Desarrollo](#-desarrollo)
- [DocumentaciÃ³n](#-documentaciÃ³n)
- [Contribuciones](#-contribuciones)

---

## ğŸ¯ CaracterÃ­sticas

### ExtracciÃ³n de Datos
- **Directorio UAM**: ExtracciÃ³n automÃ¡tica de lista de profesores del [Directorio UAM Azcapotzalco](https://sistemas.azc.uam.mx/Somos/Directorio/)
- **MisProfesores.com**: Scraping de perfiles completos con calificaciones, etiquetas y reseÃ±as
- **PaginaciÃ³n automÃ¡tica**: Sin lÃ­mite artificial de pÃ¡ginas

### Sistema de CachÃ© Inteligente
- DetecciÃ³n automÃ¡tica de cambios en nÃºmero de reseÃ±as
- Tolerancia de Â±5 reseÃ±as para evitar re-scraping innecesario
- OpciÃ³n para forzar actualizaciÃ³n cuando sea necesario

### Persistencia Triple
| Formato | UbicaciÃ³n | PropÃ³sito |
|---------|-----------|-----------|
| HTML | `data/outputs/html/` | AuditorÃ­a y re-parsing |
| JSON | `data/outputs/profesores/` | Consumo local |
| Base de Datos | PostgreSQL + MongoDB | Consultas y anÃ¡lisis |

### CLI Interactivo
```bash
python -m src.cli nombres-uam    # Extraer lista de profesores
python -m src.cli prof           # Scrapear profesor (interactivo)
python -m src.cli scrape-all     # Scrapear todos con cachÃ©
```

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SentimentInsightUAM                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    CLI      â”‚â”€â”€â”€â”€â–¶â”‚  Scrapers   â”‚â”€â”€â”€â”€â–¶â”‚   Parser    â”‚   â”‚
â”‚  â”‚  (cli.py)   â”‚     â”‚  (mp/uam)   â”‚     â”‚ (parser.py) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                               â”‚
â”‚                             â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  Persistencia                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  HTML   â”‚   â”‚  JSON   â”‚   â”‚ PostgreSQL+MongoDBâ”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Estructura del Proyecto

```
SentimentInsightUAM/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli.py                 # Interfaz de lÃ­nea de comandos
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ browser.py         # Context manager Playwright
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py        # Conexiones async
â”‚   â”‚   â”œâ”€â”€ models.py          # Modelos ORM SQLAlchemy
â”‚   â”‚   â””â”€â”€ repository.py      # Persistencia dual
â”‚   â”œâ”€â”€ mp/
â”‚   â”‚   â”œâ”€â”€ parser.py          # Parser HTML
â”‚   â”‚   â””â”€â”€ scrape_prof.py     # Scraper con cachÃ©
â”‚   â””â”€â”€ uam/
â”‚       â””â”€â”€ nombres_uam.py     # Scraper directorio UAM
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ inputs/                # Lista de profesores
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ html/              # HTML original
â”‚       â””â”€â”€ profesores/        # JSON estructurado
â”œâ”€â”€ scripts/                   # Scripts de utilidad
â”œâ”€â”€ tests/                     # Tests de integraciÃ³n
â”œâ”€â”€ docs/                      # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n Docker
â”œâ”€â”€ Makefile                   # Comandos de desarrollo
â””â”€â”€ requirements.txt           # Dependencias Python
```

Para mÃ¡s detalles, consulta [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md).

---

## ğŸš€ InstalaciÃ³n

### OpciÃ³n A: Con Docker (Recomendado)

**Requisitos**: Docker >= 20.10, Python 3.11+

```bash
# 1. Clonar repositorio
git clone https://github.com/christianpm-gh/SentimentInsightUAM.git
cd SentimentInsightUAM

# 2. Configurar variables de entorno
cp .env.docker .env

# 3. Iniciar bases de datos
make docker-up

# 4. Crear entorno virtual e instalar dependencias
python -m venv venv
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
python -m playwright install chromium

# 5. Verificar instalaciÃ³n
make db-status
python -m src.cli --help
```

### OpciÃ³n B: Sin Docker

Consulta [docs/DATABASE_SETUP.md](docs/DATABASE_SETUP.md) para instalaciÃ³n manual de PostgreSQL y MongoDB.

---

## ğŸ’» Uso

### 1. Extraer Lista de Profesores UAM
```bash
python -m src.cli nombres-uam
```
Genera `data/inputs/profesor_nombres.json` con la lista de profesores.

### 2. Scrapear Profesor Individual

**Modo interactivo:**
```bash
python -m src.cli prof
```

**Por nombre:**
```bash
python -m src.cli prof --name "Juan PÃ©rez GarcÃ­a"
```

### 3. Scrapear Todos los Profesores
```bash
python -m src.cli scrape-all
```

**Salida ejemplo:**
```
Iniciando scraping de 150 profesores...
================================================================================

[1/150] Procesando: Juan Perez Garcia
  -> Scrapeado exitosamente (47 reseÃ±as)

[2/150] Procesando: Maria Lopez Hernandez
  -> Cache vigente (32 reseÃ±as)

================================================================================
RESUMEN DE SCRAPING
================================================================================
Total profesores procesados: 150
Scrapeados exitosamente: 28
Obtenidos de cache: 119
Errores: 3
================================================================================
```

### Formato de Salida JSON

```json
{
  "name": "Nombre del Profesor",
  "overall_quality": 9.5,
  "difficulty": 7.2,
  "recommend_percent": 95.0,
  "cached": false,
  "tags": [{"label": "EXCELENTE CLASE", "count": 25}],
  "reviews": [
    {
      "date": "2024-01-15",
      "course": "Estructura de Datos",
      "overall": 10.0,
      "ease": 8.0,
      "attendance": "Obligatoria",
      "grade_received": "10",
      "interest": "Alta",
      "tags": ["BUENA ONDA"],
      "comment": "Excelente profesor..."
    }
  ]
}
```

---

## ğŸ”„ Flujos CrÃ­ticos

### Flujo de CachÃ© Inteligente

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Solicitar datos â”‚
â”‚ de profesor     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â¿Existe cachÃ©?     â”‚â”€â”€Noâ”€â–¶ Scrapear nuevo  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ SÃ­
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â¿CambiÃ³ nÃºmero de  â”‚â”€â”€Noâ”€â–¶ Retornar cachÃ©  â”‚
â”‚ reseÃ±as (Â±5)?      â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ SÃ­
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scrapear nuevo  â”‚
â”‚ y actualizar    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Persistencia

```
Datos scrapeados
       â”‚
       â”œâ”€â”€â–¶ Guardar HTML (auditorÃ­a)
       â”œâ”€â”€â–¶ Guardar JSON (local)
       â””â”€â”€â–¶ Guardar en BD (PostgreSQL + MongoDB)
```

---

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno (`.env`)

```env
# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=sentiment_uam_db
POSTGRES_USER=sentiment_admin
POSTGRES_PASSWORD=dev_password_2024

# MongoDB
MONGO_HOST=localhost
MONGO_PORT=27017
MONGO_DB=sentiment_uam_nlp
MONGO_USER=sentiment_admin
MONGO_PASSWORD=dev_password_2024

# Scraper
HEADLESS=true
```

### Comandos Make

```bash
make help              # Ver comandos disponibles
make docker-up         # Iniciar BD
make docker-down       # Detener BD
make db-status         # Estado de BD
make db-psql           # Shell PostgreSQL
make db-mongo          # Shell MongoDB
make install           # Instalar dependencias
```

### Script de Limpieza de BD

```bash
python scripts/clean_databases.py          # Modo interactivo
python scripts/clean_databases.py --all    # Limpiar todo
python scripts/clean_databases.py --verify # Solo verificar
```

---

## ğŸ› ï¸ Desarrollo

### ConfiguraciÃ³n del Entorno

```bash
# Clonar y entrar al directorio
git clone https://github.com/christianpm-gh/SentimentInsightUAM.git
cd SentimentInsightUAM

# Crear y activar venv
python -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
python -m playwright install chromium

# Iniciar BD
make docker-up
```

### Ejecutar Tests

```bash
# Test de integraciÃ³n de BD
python tests/test_database_integration.py

# Test de scraping
python tests/test_scrape_josue_padilla.py
```

Para mÃ¡s detalles, consulta [docs/DEVELOPMENT_GUIDE.md](docs/DEVELOPMENT_GUIDE.md).

---

## ğŸ“š DocumentaciÃ³n

| Documento | DescripciÃ³n |
|-----------|-------------|
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | Arquitectura del sistema |
| [TECHNICAL_DOCUMENTATION.md](docs/TECHNICAL_DOCUMENTATION.md) | DocumentaciÃ³n tÃ©cnica detallada |
| [DEVELOPMENT_GUIDE.md](docs/DEVELOPMENT_GUIDE.md) | GuÃ­a para desarrolladores |
| [DATABASE_DESIGN.md](docs/DATABASE_DESIGN.md) | DiseÃ±o de bases de datos |
| [DATABASE_SETUP.md](docs/DATABASE_SETUP.md) | ConfiguraciÃ³n manual de BD |
| [DOCKER_SETUP.md](docs/DOCKER_SETUP.md) | ConfiguraciÃ³n con Docker |

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Consulta:

- [CONTRIBUTING.md](.github/CONTRIBUTING.md) - GuÃ­a de contribuciÃ³n
- [COMMIT_CONVENTION.md](.github/COMMIT_CONVENTION.md) - ConvenciÃ³n de commits
- [BRANCH_NAMING.md](.github/BRANCH_NAMING.md) - Nombres de ramas
- [PULL_REQUEST_TEMPLATE.md](.github/PULL_REQUEST_TEMPLATE.md) - Template para PRs

---

## ğŸ”® Roadmap

- [x] Persistencia en PostgreSQL + MongoDB (v1.2.0)
- [x] Script de limpieza de BD (v1.2.0)
- [x] Fix de bug de paginaciÃ³n (v1.2.1)
- [ ] AnÃ¡lisis de sentimiento con BERT
- [ ] API REST con FastAPI
- [ ] Jobs programados
- [ ] Dashboard de visualizaciÃ³n

---

## ğŸ“ Notas Importantes

- **Uso responsable**: Este scraper es para fines educativos
- **Rate limiting**: Incluye delays aleatorios para evitar sobrecarga
- **CachÃ© automÃ¡tico**: Evita scraping redundante
- **Timeouts**: 45s navegaciÃ³n, 30s selectores

---

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto para fines educativos.

## ğŸ‘¥ Equipo

Desarrollado por el equipo de SentimentInsightUAM - UAM Azcapotzalco

---

**âš ï¸ Disclaimer**: Este proyecto es con fines educativos y de investigaciÃ³n. El uso debe cumplir con los TÃ©rminos de Servicio de los sitios web utilizados.
