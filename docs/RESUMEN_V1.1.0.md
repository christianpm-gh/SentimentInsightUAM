# Resumen Ejecutivo - Implementaci√≥n de Persistencia v1.1.0

**Proyecto**: SentimentInsightUAM  
**Fecha**: 2025-11-08  
**Versi√≥n**: 1.1.0 (Dise√±o Completo de Persistencia)  
**Estado**: ‚úÖ Dise√±o Aprobado - Listo para Implementaci√≥n

---

## üìä An√°lisis Realizado

### 1. Scraping de Profesores Reales

Se ejecut√≥ el scraper con dos profesores de la UAM Azcapotzalco:

#### Josue Padilla Cuevas
- **Rese√±as**: 38
- **Calidad**: 9.4/10
- **Dificultad**: 2.9/10
- **Recomendaci√≥n**: 97%
- **Archivo**: `data/outputs/profesores/josue-padilla-cuevas.json`

#### Rodrigo Alexander Castro Campos
- **Rese√±as**: 75
- **Calificaciones**: 8.6/10
- **Dificultad**: 5.0/10
- **Recomendaci√≥n**: 79%
- **Archivo**: `data/outputs/profesores/rodrigo-alexander-castro-campos.json`

### 2. Estructura de Datos Identificada

```json
{
  "name": "Nombre - Instituci√≥n - Fuente",
  "overall_quality": 9.4,
  "difficulty": 2.9,
  "recommend_percent": 97.0,
  "tags": [{"label": "ETIQUETA", "count": 11}],
  "reviews": [
    {
      "date": "2025-08-09",
      "course": "Bases de Datos",
      "overall": 8.0,
      "ease": 8.0,
      "attendance": "Obligatoria",
      "grade_received": "23",
      "interest": "Alto",
      "tags": ["Tag1", "Tag2"],
      "comment": "Texto del comentario para an√°lisis NLP..."
    }
  ]
}
```

**Campos clave identificados**:
- ‚úÖ M√©tricas num√©ricas (calidad, dificultad, recomendaci√≥n)
- ‚úÖ Etiquetas con contadores (tags del perfil)
- ‚úÖ Rese√±as con metadata estructurada
- ‚úÖ **Comentarios textuales** ‚Üí Target para an√°lisis de sentimiento BERT

---

## üóÑÔ∏è Arquitectura de Bases de Datos Dise√±ada

### Dual Database Pattern

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL (sentiment_uam_db)        ‚îÇ
‚îÇ   - Profesores                         ‚îÇ
‚îÇ   - Perfiles (snapshots temporales)    ‚îÇ
‚îÇ   - Rese√±as (metadata estructurada)    ‚îÇ
‚îÇ   - Cursos                             ‚îÇ
‚îÇ   - Etiquetas                          ‚îÇ
‚îÇ   - Historial de scraping              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îÇ mongo_opinion_id
                 ‚îÇ (v√≠nculo)
                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MongoDB (sentiment_uam_nlp)          ‚îÇ
‚îÇ   - Opiniones textuales                ‚îÇ
‚îÇ   - An√°lisis de sentimiento BERT       ‚îÇ
‚îÇ   - Embeddings vectoriales (768 dims)  ‚îÇ
‚îÇ   - Cache de an√°lisis                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Razones del Dise√±o Dual

**PostgreSQL** (Datos Estructurados):
- ‚úÖ Integridad referencial (relaciones FK)
- ‚úÖ JOINs complejos para estad√≠sticas
- ‚úÖ √çndices num√©ricos eficientes
- ‚úÖ Transacciones ACID
- ‚úÖ Vistas materializadas para dashboards

**MongoDB** (An√°lisis NLP):
- ‚úÖ Almacenamiento flexible de texto largo
- ‚úÖ Documentos con estructura anidada (sentimiento)
- ‚úÖ B√∫squeda full-text nativa en espa√±ol
- ‚úÖ Escalabilidad horizontal
- ‚úÖ Ideal para embeddings y vectores BERT

---

## üìã Tablas PostgreSQL (8 principales)

### 1. `profesores`
- **Prop√≥sito**: Cat√°logo maestro de profesores
- **Campos clave**: `nombre_completo`, `nombre_limpio`, `slug`, URLs
- **√çndices**: slug (unique), nombre_limpio, departamento

### 2. `perfiles`
- **Prop√≥sito**: Snapshots temporales de m√©tricas
- **Campos clave**: `calidad_general`, `dificultad`, `porcentaje_recomendacion`
- **Constraint**: UNIQUE(profesor_id, DATE(fecha_extraccion)) ‚Üí No duplicados por d√≠a

### 3. `etiquetas`
- **Prop√≥sito**: Cat√°logo unificado de tags
- **Campos clave**: `etiqueta`, `etiqueta_normalizada`, `categoria`, `uso_total`
- **Seed**: 21 etiquetas comunes categorizadas

### 4. `perfil_etiquetas`
- **Prop√≥sito**: Many-to-many entre perfiles y etiquetas
- **Campos clave**: `perfil_id`, `etiqueta_id`, `contador`
- **Trigger**: Actualiza `uso_total` autom√°ticamente

### 5. `cursos`
- **Prop√≥sito**: Cat√°logo de materias
- **Campos clave**: `nombre`, `nombre_normalizado`, `codigo`, `departamento`

### 6. `resenias_metadata`
- **Prop√≥sito**: Datos estructurados de rese√±as (sin comentario textual)
- **Campos clave**: `calidad_general`, `facilidad`, `asistencia`, `mongo_opinion_id`
- **V√≠nculo**: `mongo_opinion_id` ‚Üí MongoDB ObjectId

### 7. `resenia_etiquetas`
- **Prop√≥sito**: Many-to-many entre rese√±as y etiquetas

### 8. `historial_scraping`
- **Prop√≥sito**: Auditor√≠a completa de ejecuciones
- **Campos clave**: `estado`, `resenias_encontradas`, `duracion_segundos`, `cache_utilizado`

### Vistas Optimizadas

#### `perfiles_actuales`
- Vista simple con √∫ltimo perfil de cada profesor (DISTINCT ON)

#### `stats_profesores` (Materializada)
- Estad√≠sticas pre-calculadas para dashboards
- Incluye: promedios hist√≥ricos, distribuci√≥n de asistencia, top 3 etiquetas
- Funci√≥n: `refresh_stats_profesores()` para actualizaci√≥n programada

---

## üçÉ Colecciones MongoDB (2 principales)

### 1. `opiniones`
```javascript
{
  _id: ObjectId("..."),
  profesor_id: 1,
  resenia_id: 123,  // V√≠nculo con PostgreSQL
  comentario: "Texto completo...",
  sentimiento: {
    analizado: false,  // true cuando BERT lo procese
    puntuacion: null,  // -1 a 1
    clasificacion: null,  // "positivo", "neutral", "negativo"
    aspectos: {
      explicacion: null,
      disponibilidad: null,
      evaluacion: null,
      carga_trabajo: null
    },
    modelo_version: null,
    fecha_analisis: null
  },
  embedding: null,  // Array de 768 floats (BERT)
  fecha_opinion: ISODate("..."),
  fecha_extraccion: ISODate("...")
}
```

**Validaci√≥n**: JSON Schema estricto (campos requeridos, rangos, enums)

### 2. `sentimiento_cache`
- Cache de an√°lisis para evitar reprocesamiento
- TTL index: Auto-eliminaci√≥n despu√©s de 90 d√≠as sin uso

### √çndices MongoDB (8 especializados)

1. **Compuesto**: `profesor_id + fecha_opinion` (consultas comunes)
2. **Parcial**: `sentimiento.analizado = false` (worker BERT)
3. **Compuesto**: `clasificacion + puntuacion` (filtrado)
4. **Full-text**: `comentario + curso` en espa√±ol
5. **Simple**: `curso` (b√∫squeda por materia)
6. **Temporal**: `fecha_opinion` DESC
7. **√önico**: `resenia_id` (v√≠nculo PostgreSQL)
8. **Simple**: `profesor_slug`

---

## üìÅ Archivos Creados

### Scripts de Inicializaci√≥n

#### `scripts/init_postgres.sql` (400+ l√≠neas)
- Creaci√≥n de base de datos con encoding UTF-8
- Instalaci√≥n de extensiones: `unaccent`, `pg_trgm`
- 8 tablas con documentaci√≥n inline
- 20+ √≠ndices estrat√©gicos
- 4 funciones PL/pgSQL
- 3 triggers autom√°ticos
- 2 vistas (1 materializada)
- Seed de 21 etiquetas categorizadas
- Validaci√≥n autom√°tica al finalizar

#### `scripts/init_mongo.js` (300+ l√≠neas)
- Creaci√≥n de colecci√≥n con validaci√≥n JSON Schema
- 8 √≠ndices especializados
- 3 funciones auxiliares en `system.js`
- TTL index para cache (90 d√≠as)
- Estad√≠sticas de validaci√≥n

### Documentaci√≥n

#### `docs/DATABASE_DESIGN.md` (3500+ l√≠neas)
Contenido:
1. An√°lisis de datos del scraping
2. Arquitectura dual database (justificaci√≥n)
3. Esquemas PostgreSQL detallados (con ejemplos)
4. Esquemas MongoDB detallados (con ejemplos)
5. Diagramas de relaciones
6. Flujo de sincronizaci√≥n entre BD
7. C√≥digo ejemplo de integraci√≥n
8. Vistas materializadas para dashboards
9. 4 casos de uso con consultas SQL/MongoDB
10. Checklist completo de implementaci√≥n

#### `docs/DATABASE_SETUP.md` (2000+ l√≠neas)
Contenido:
1. Requisitos previos
2. Instalaci√≥n de PostgreSQL (Ubuntu, macOS, Fedora)
3. Instalaci√≥n de MongoDB (Ubuntu, macOS, Fedora)
4. Configuraci√≥n de autenticaci√≥n y usuarios
5. Creaci√≥n de permisos granulares
6. Ejecuci√≥n de scripts de inicializaci√≥n
7. Verificaci√≥n completa de ambas BD
8. Configuraci√≥n de variables de entorno (.env)
9. Troubleshooting de 8 errores comunes
10. Consultas SQL/MongoDB de validaci√≥n

---

## üéØ Plan de Implementaci√≥n

### Fase 1: Persistencia (v1.2.0) - Pr√≥xima

**M√≥dulos a Crear**:

1. **`src/db/__init__.py`**
   - Exports de conexiones y modelos

2. **`src/db/postgres.py`**
   - Engine async con SQLAlchemy 2.0
   - Connection pool configurado
   - Session factory async

3. **`src/db/mongodb.py`**
   - Cliente Motor (async)
   - Conexi√≥n a base de datos
   - Helper de colecciones

4. **`src/db/models.py`**
   - Modelos ORM de 8 tablas
   - Relaciones declarativas
   - Validaciones con Pydantic

5. **`src/db/sync.py`**
   - Funci√≥n `guardar_profesor_completo(data)`
   - L√≥gica de sincronizaci√≥n PostgreSQL ‚Üî MongoDB
   - Transacciones ACID
   - Manejo de errores

**Integraci√≥n con Scraper**:

Modificar `src/mp/scrape_prof.py`:
```python
async def find_and_scrape(...):
    # ...c√≥digo existente...
    
    # Nueva l√≥gica de persistencia
    try:
        from src.db.sync import guardar_profesor_completo
        profesor_id = await guardar_profesor_completo(prof)
        print(f"‚úì Persistido en BD (profesor_id: {profesor_id})")
    except Exception as e:
        print(f"‚ö† Error en persistencia: {e}")
        # Continuar guardando JSON como fallback
    
    # Mantener guardado de JSON para auditor√≠a
    html_path = _save_html(prof_name, all_html_pages[0])
    json_path = _save_json(prof_name, prof)
```

**Testing**:
- Scrapear 10 profesores de prueba
- Verificar inserci√≥n en PostgreSQL
- Verificar inserci√≥n en MongoDB
- Validar v√≠nculos entre BD
- Ejecutar consultas de ejemplo

---

## üîß Configuraci√≥n Requerida

### Bases de Datos

**PostgreSQL**:
- Versi√≥n: >= 15.0
- Base de datos: `sentiment_uam_db`
- Usuario: `sentiment_admin`
- Extensiones: `unaccent`, `pg_trgm`

**MongoDB**:
- Versi√≥n: >= 7.0
- Base de datos: `sentiment_uam_nlp`
- Usuario: `sentiment_admin`
- Autenticaci√≥n: Habilitada

### Variables de Entorno (.env)

```env
# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=sentiment_uam_db
POSTGRES_USER=sentiment_admin
POSTGRES_PASSWORD=tu_contrase√±a_segura

# MongoDB
MONGO_HOST=localhost
MONGO_PORT=27017
MONGO_DB=sentiment_uam_nlp
MONGO_USER=sentiment_admin
MONGO_PASSWORD=tu_contrase√±a_segura

# URLs de Conexi√≥n
DATABASE_URL=postgresql+asyncpg://sentiment_admin:password@localhost:5432/sentiment_uam_db
MONGO_URL=mongodb://sentiment_admin:password@localhost:27017/sentiment_uam_nlp
```

### Dependencias Python (Nuevas)

```txt
# Agregar a requirements.txt
sqlalchemy[asyncio]>=2.0.0
asyncpg>=0.29.0
motor>=3.3.0
pymongo>=4.6.0
```

---

## üìä M√©tricas del Dise√±o

### Complejidad

**PostgreSQL**:
- 8 tablas principales
- 2 vistas (1 materializada)
- 20+ √≠ndices optimizados
- 4 funciones PL/pgSQL
- 3 triggers autom√°ticos
- 21 etiquetas seed

**MongoDB**:
- 2 colecciones
- 8 √≠ndices especializados
- 3 funciones auxiliares
- Validaci√≥n JSON Schema completa

### Documentaci√≥n

- **3500+ l√≠neas** de dise√±o t√©cnico
- **2000+ l√≠neas** de gu√≠a de configuraci√≥n
- **400+ l√≠neas** de SQL
- **300+ l√≠neas** de JavaScript
- **Cobertura 100%** de casos de uso

### Capacidad Estimada

**Por Profesor**:
- 1 registro en `profesores`
- 1+ registros en `perfiles` (snapshots temporales)
- 10-100 registros en `resenias_metadata`
- 10-100 documentos en `opiniones` (MongoDB)
- 50-500 relaciones en `perfil_etiquetas` y `resenia_etiquetas`

**Escalabilidad**:
- 150 profesores actuales ‚Üí ~15,000 rese√±as ‚Üí ~10,000 opiniones con comentario
- Estimado para 500 profesores ‚Üí ~50,000 rese√±as ‚Üí ~35,000 opiniones
- PostgreSQL maneja millones de filas sin problema
- MongoDB optimizado para cientos de miles de documentos

---

## üöÄ Pr√≥ximos Pasos Inmediatos

### 1. Configurar Bases de Datos (1-2 horas)

```bash
# PostgreSQL
sudo apt install postgresql-15
psql -U postgres -f scripts/init_postgres.sql

# MongoDB
sudo apt install mongodb-org
mongosh sentiment_uam_nlp scripts/init_mongo.js

# Verificar
psql -U sentiment_admin -d sentiment_uam_db -c "\dt"
mongosh -u sentiment_admin -p sentiment_uam_nlp --eval "db.getCollectionNames()"
```

### 2. Instalar Dependencias Python (5 min)

```bash
pip install sqlalchemy[asyncio] asyncpg motor pymongo
```

### 3. Crear M√≥dulos de Persistencia (4-6 horas)

- `src/db/postgres.py` ‚Üí Conexi√≥n SQLAlchemy async
- `src/db/mongodb.py` ‚Üí Conexi√≥n Motor async
- `src/db/models.py` ‚Üí Modelos ORM
- `src/db/sync.py` ‚Üí L√≥gica de sincronizaci√≥n

### 4. Integrar con Scraper (2 horas)

- Modificar `src/mp/scrape_prof.py`
- Agregar llamada a `guardar_profesor_completo()`
- Testing con 10 profesores

### 5. Validaci√≥n y Testing (2 horas)

- Ejecutar `scrape-all` con subset
- Verificar integridad en PostgreSQL
- Verificar v√≠nculo con MongoDB
- Ejecutar consultas de validaci√≥n

---

## üìà Beneficios del Dise√±o

### T√©cnicos

‚úÖ **Separaci√≥n de responsabilidades**: Datos estructurados vs texto libre  
‚úÖ **Optimizaci√≥n espec√≠fica**: √çndices num√©ricos vs full-text  
‚úÖ **Escalabilidad**: PostgreSQL + MongoDB se escalan independientemente  
‚úÖ **Integridad de datos**: Constraints y validaci√≥n en ambas BD  
‚úÖ **Historial temporal**: Snapshots de m√©tricas por fecha  
‚úÖ **Auditor√≠a completa**: Registro de cada scraping

### Funcionales

‚úÖ **An√°lisis de sentimiento**: Estructura preparada para BERT  
‚úÖ **B√∫squeda sem√°ntica**: Embeddings vectoriales (futuro)  
‚úÖ **Estad√≠sticas r√°pidas**: Vistas materializadas  
‚úÖ **Consultas complejas**: JOINs y agregaciones optimizadas  
‚úÖ **Cache inteligente**: Evita reprocesamiento de an√°lisis  
‚úÖ **API ready**: Estructura lista para endpoints REST

### Desarrollo

‚úÖ **Documentaci√≥n exhaustiva**: Gu√≠as paso a paso  
‚úÖ **Scripts automatizados**: Inicializaci√≥n con un comando  
‚úÖ **Validaci√≥n autom√°tica**: Schemas y constraints  
‚úÖ **Patrones establecidos**: Async, ORM, best practices  
‚úÖ **Troubleshooting**: 8 problemas comunes documentados  

---

## üéì Lecciones Aprendidas del An√°lisis

### Del Scraping Real

1. **Nombres inconsistentes**: Incluyen instituci√≥n en el texto ‚Üí Necesita limpieza
2. **Cursos con alias**: "POO" = "Programaci√≥n Orientada a Objetos" ‚Üí Normalizaci√≥n
3. **Comentarios vac√≠os**: Algunos reviews no tienen texto ‚Üí Validar `tiene_comentario`
4. **Etiquetas con contador null**: Manejar con `count or 0`
5. **Fechas futuras**: Algunos reviews tienen fecha 2025-08-09 ‚Üí Validar en an√°lisis

### Del Dise√±o de BD

1. **Dual database pattern**: Ideal para NLP + estad√≠sticas
2. **Snapshots temporales**: Crucial para an√°lisis de tendencias
3. **Normalizaci√≥n de etiquetas**: Evita duplicados ("CALIFICA DURO" vs "Califica duro")
4. **V√≠nculo MongoDB-PostgreSQL**: ObjectId como string funciona bien
5. **Vistas materializadas**: Esenciales para dashboards con JOINs complejos

---

## üìù Convenci√≥n de Commits para v1.1.0

```bash
git add docs/ scripts/

git commit -m "feat: Implementar dise√±o completo de persistencia PostgreSQL y MongoDB

- Crear esquemas PostgreSQL (8 tablas, 2 vistas, 20+ √≠ndices)
- Crear esquemas MongoDB (2 colecciones, 8 √≠ndices)
- Agregar scripts de inicializaci√≥n (init_postgres.sql, init_mongo.js)
- Documentar arquitectura completa (DATABASE_DESIGN.md)
- Documentar configuraci√≥n paso a paso (DATABASE_SETUP.md)
- Analizar datos reales de scraping (Josue Padilla, Rodrigo Castro)
- Preparar estructura para an√°lisis BERT y embeddings vectoriales

BREAKING CHANGE: Nueva arquitectura requiere PostgreSQL 15+ y MongoDB 7.0+
Se requiere ejecutar scripts de inicializaci√≥n antes de usar persistencia."

git tag -a v1.1.0 -m "Version 1.1.0: Dise√±o completo de persistencia dual (PostgreSQL + MongoDB)"
```

---

## üèÅ Conclusi√≥n

El dise√±o de persistencia v1.1.0 est√° **completo y listo para implementaci√≥n**. Se ha realizado un an√°lisis exhaustivo de los datos reales del scraper, dise√±ado una arquitectura dual database optimizada para an√°lisis de sentimiento, creado scripts de inicializaci√≥n automatizados y documentado paso a paso todo el proceso.

**Estado actual**: ‚úÖ Dise√±o aprobado  
**Pr√≥ximo hito**: v1.2.0 - Implementaci√≥n de m√≥dulos de persistencia Python  
**Tiempo estimado**: 8-10 horas de desarrollo + testing

---

**Versi√≥n**: 1.1.0  
**Fecha**: 2025-11-08  
**Autor**: Equipo SentimentInsightUAM  
**Mantenedores**: UAM Azcapotzalco
